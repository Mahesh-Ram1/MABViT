JAX implementation of Modified attention. 


How to use: Download Modiefied.attention.py and Call Modified_attention.MultiHeadDotProductAttention instead of flax.linen.MultiHeadDotProductAttention.
